{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NAS_Ac.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKuxTWsd5xej",
        "colab_type": "code",
        "outputId": "a8daa14e-f6d4-4698-fe17-a5493129d3a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Conv2D, GlobalAveragePooling2D\n",
        "from keras.datasets import cifar10, mnist, fashion_mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from utils import StateSpace, Controller\n",
        "\n",
        "\n",
        "NUM_LAYERS = 4\n",
        "MAX_TRIALS = 20\n",
        "\n",
        "EPOCHS = 10\n",
        "BATCHSIZE = 250\n",
        "EXPLORATION = 0.9\n",
        "REGULARIZATION = 1e-2\n",
        "CONTROLLER_CELLS = 32\n",
        "EMBEDDING_DIM = 20\n",
        "ACCURACY_BETA = 0.8\n",
        "CLIP_REWARDS = 0.0\n",
        "RESTORE_CONTROLLER = True\n",
        "\n",
        "policy_sess = tf.Session()\n",
        "K.set_session(policy_sess)\n",
        "\n",
        "state_space=StateSpace()\n",
        "state_space.add_state(name='kernel', values=[1, 3])\n",
        "state_space.add_state(name='filters', values=[32, 48, 64])\n",
        "state_space.print_state_space()\n",
        "\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train = X_train.astype('float32') / 255.\n",
        "X_test = X_test.astype('float32') / 255.\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
        "    X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
        "    print(X_train.shape)\n",
        "    input_shape = (1, 28, 28)\n",
        "else:\n",
        "    X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "    input_shape = (28, 28, 1)\n",
        "dataset = [X_train, y_train, X_test, y_test]\n",
        "previous_acc = 0.0\n",
        "total_reward = 0.0\n",
        "\n",
        "class NetworkManager:\n",
        "    def __init__(self, dataset, epochs=5, batchsize=128, acc_beta=0.8, clip_rewards=0.0):\n",
        "        self.dataset = dataset\n",
        "        self.epochs = epochs\n",
        "        self.batchsize = batchsize\n",
        "        self.clip_rewards = clip_rewards\n",
        "\n",
        "        self.beta = acc_beta\n",
        "        self.beta_bias = acc_beta\n",
        "        self.moving_acc = 0.0\n",
        "    def get_rewards(self, model_fn, actions):\n",
        "        with tf.Session(graph=tf.Graph()) as network_sess:\n",
        "            K.set_session(network_sess)\n",
        "            model = model_fn(actions)\n",
        "            model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
        "            X_train, y_train, X_val, y_val = self.dataset\n",
        "            model.fit(X_train, y_train, batch_size=self.batchsize, epochs=self.epochs,\n",
        "                      verbose=1, validation_data=(X_val, y_val),\n",
        "                      callbacks=[ModelCheckpoint('weights/temp_network.h5',\n",
        "                                                 monitor='val_acc', verbose=1,\n",
        "                                                 save_best_only=True,\n",
        "                                                 save_weights_only=True)])\n",
        "            model.load_weights('weights/temp_network.h5')\n",
        "            loss, acc = model.evaluate(X_val, y_val, batch_size=self.batchsize)\n",
        "            reward = (acc - self.moving_acc)\n",
        "            if self.clip_rewards:\n",
        "                reward = np.clip(reward, -0.05, 0.05)\n",
        "            if self.beta > 0.0 and self.beta < 1.0:\n",
        "                self.moving_acc = self.beta * self.moving_acc + (1 - self.beta) * acc\n",
        "                self.moving_acc = self.moving_acc / (1 - self.beta_bias)\n",
        "                self.beta_bias = 0\n",
        "                reward = np.clip(reward, -0.1, 0.1)\n",
        "            print()\n",
        "            print(\"Manager: EWA Accuracy = \", self.moving_acc)\n",
        "        network_sess.close()\n",
        "        return reward, acc\n",
        "\n",
        "\n",
        "def model_fn(actions):\n",
        "    kernel_1, filters_1, kernel_2, filters_2, kernel_3, filters_3, kernel_4, filters_4 = actions\n",
        "    ip = Input(shape=(28, 28, 1))\n",
        "    x = Conv2D(filters_1, (kernel_1, kernel_1), strides=(2, 2), padding='same', activation='relu')(ip)\n",
        "    x = Conv2D(filters_2, (kernel_2, kernel_2), strides=(1, 1), padding='same', activation='relu')(x)\n",
        "    x = Conv2D(filters_3, (kernel_3, kernel_3), strides=(2, 2), padding='same', activation='relu')(x)\n",
        "    x = Conv2D(filters_4, (kernel_4, kernel_4), strides=(1, 1), padding='same', activation='relu')(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(10, activation='softmax')(x)\n",
        "    model = Model(ip, x)\n",
        "    return model\n",
        "\n",
        "with policy_sess.as_default():\n",
        "    controller = Controller(policy_sess, NUM_LAYERS, state_space,\n",
        "                            reg_param=REGULARIZATION,\n",
        "                            exploration=EXPLORATION,\n",
        "                            controller_cells=CONTROLLER_CELLS,\n",
        "                            embedding_dim=EMBEDDING_DIM,\n",
        "                            restore_controller=RESTORE_CONTROLLER)\n",
        "\n",
        "manager = NetworkManager(dataset, epochs=EPOCHS, batchsize=BATCHSIZE, clip_rewards=CLIP_REWARDS,\n",
        "                         acc_beta=ACCURACY_BETA)\n",
        "\n",
        "state = state_space.get_random_state_space(NUM_LAYERS)\n",
        "print(\"Initial Random State : \", state_space.parse_state_space_list(state))\n",
        "print()\n",
        "\n",
        "accuracy_plot = []\n",
        "reward_plot = []\n",
        "loss_plot = []\n",
        "\n",
        "for trial in range(MAX_TRIALS):\n",
        "    with policy_sess.as_default():\n",
        "        K.set_session(policy_sess)\n",
        "        actions = controller.get_action(state) \n",
        "\n",
        "    state_space.print_actions(actions)\n",
        "    print(\"Predicted actions : \", state_space.parse_state_space_list(actions))\n",
        "    \n",
        "    reward, previous_acc = manager.get_rewards(model_fn, state_space.parse_state_space_list(actions))\n",
        "    print(\"Rewards : \", reward, \"Accuracy : \", previous_acc)\n",
        "   \n",
        "    with policy_sess.as_default():\n",
        "        K.set_session(policy_sess)\n",
        "        temp_action=controller.get_action(state) ## will get the next action; new model\n",
        "    next_reward, next_acc = manager.get_rewards(model_fn,state_space.parse_state_space_list(temp_action))\n",
        "    next_reward=0.7*next_reward\n",
        "    reward+=next_reward\n",
        "    print(\"Rewards : \", reward,\"Next Reward: \", next_reward, \"Accuracy : \", next_acc)\n",
        "    reward_plot.append(reward)\n",
        "    \n",
        "    accuracy_plot.append(next_acc)\n",
        "\n",
        "    with policy_sess.as_default():\n",
        "        K.set_session(policy_sess)\n",
        "        total_reward += reward\n",
        "        print(\"Total reward : \", total_reward)\n",
        "        state = actions\n",
        "        controller.store_rollout(state, reward)\n",
        "        loss = controller.train_step()\n",
        "        loss_plot.append(loss)\n",
        "        print(\"Trial %d: Controller loss : %0.6f\" % (trial + 1, loss))\n",
        "        with open('train_history.csv', mode='a+') as f:\n",
        "            data = [previous_acc, reward]\n",
        "            data.extend(state_space.parse_state_space_list(state))\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow(data)\n",
        "    print()\n",
        "print(\"Total Reward : \", total_reward)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "**************************************** STATE SPACE ****************************************\n",
            "{ 'id': 0,\n",
            "  'index_map_': {0: 1, 1: 3},\n",
            "  'name': 'kernel',\n",
            "  'size': 2,\n",
            "  'value_map_': {1: 0, 3: 1},\n",
            "  'values': [1, 3]}\n",
            "\n",
            "{ 'id': 1,\n",
            "  'index_map_': {0: 32, 1: 48, 2: 64},\n",
            "  'name': 'filters',\n",
            "  'size': 3,\n",
            "  'value_map_': {32: 0, 48: 1, 64: 2},\n",
            "  'values': [32, 48, 64]}\n",
            "\n",
            "WARNING:tensorflow:From /content/utils.py:173: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/utils.py:175: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/utils.py:177: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /content/utils.py:181: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/utils.py:187: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/utils.py:203: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /content/utils.py:205: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/utils.py:217: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/utils.py:217: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/utils.py:221: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/utils.py:224: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/utils.py:225: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /content/utils.py:257: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/utils.py:261: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/utils.py:263: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/utils.py:264: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/utils.py:269: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Loading Controller Checkpoint !\n",
            "INFO:tensorflow:Restoring parameters from weights/controller.ckpt-5\n",
            "Initial Random State :  [1, 64, 1, 48, 3, 48, 1, 64]\n",
            "\n",
            "Generating random action to explore\n",
            "Actions :\n",
            "******************** Layer 1 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 0.0), (48, 0.0), (64, 3.0)]\n",
            "******************** Layer 2 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 0.0), (48, 2.0), (64, 0.0)]\n",
            "******************** Layer 3 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 0.0), (48, 0.0), (64, 3.0)]\n",
            "******************** Layer 4 ********************\n",
            "kernel :  [(1, 1.0), (3, 0.0)]\n",
            "filters :  [(32, 1.0), (48, 0.0), (64, 0.0)]\n",
            "\n",
            "Predicted actions :  [3, 64, 3, 48, 3, 64, 1, 32]\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 1.2035 - acc: 0.5646 - val_loss: 0.7985 - val_acc: 0.7200\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.72000, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.7412 - acc: 0.7336 - val_loss: 0.7051 - val_acc: 0.7525\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.72000 to 0.75250, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.6771 - acc: 0.7536 - val_loss: 0.6473 - val_acc: 0.7683\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.75250 to 0.76830, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.6184 - acc: 0.7768 - val_loss: 0.6399 - val_acc: 0.7714\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.76830 to 0.77140, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.5877 - acc: 0.7910 - val_loss: 0.5822 - val_acc: 0.7945\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.77140 to 0.79450, saving model to weights/temp_network.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.5679 - acc: 0.7975 - val_loss: 0.5642 - val_acc: 0.8036\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.79450 to 0.80360, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.5318 - acc: 0.8126 - val_loss: 0.5637 - val_acc: 0.7917\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80360\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.5241 - acc: 0.8141 - val_loss: 0.5272 - val_acc: 0.8183\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.80360 to 0.81830, saving model to weights/temp_network.h5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.4953 - acc: 0.8235 - val_loss: 0.4901 - val_acc: 0.8298\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.81830 to 0.82980, saving model to weights/temp_network.h5\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.4770 - acc: 0.8311 - val_loss: 0.4831 - val_acc: 0.8330\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.82980 to 0.83300, saving model to weights/temp_network.h5\n",
            "10000/10000 [==============================] - 0s 24us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.8329999968409538\n",
            "Rewards :  0.1 Accuracy :  0.8329999968409538\n",
            "Prediction action from Controller\n",
            "State input to Controller for Action :  [1. 0.]\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 73us/step - loss: 1.1679 - acc: 0.5758 - val_loss: 0.7949 - val_acc: 0.7142\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.71420, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.7485 - acc: 0.7266 - val_loss: 0.7098 - val_acc: 0.7395\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.71420 to 0.73950, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.6897 - acc: 0.7487 - val_loss: 0.6570 - val_acc: 0.7605\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.73950 to 0.76050, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.6381 - acc: 0.7698 - val_loss: 0.6291 - val_acc: 0.7734\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.76050 to 0.77340, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.5966 - acc: 0.7853 - val_loss: 0.6128 - val_acc: 0.7797\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.77340 to 0.77970, saving model to weights/temp_network.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.5718 - acc: 0.7927 - val_loss: 0.5708 - val_acc: 0.7943\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.77970 to 0.79430, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.5393 - acc: 0.8038 - val_loss: 0.5517 - val_acc: 0.8015\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.79430 to 0.80150, saving model to weights/temp_network.h5\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.5136 - acc: 0.8149 - val_loss: 0.5239 - val_acc: 0.8132\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.80150 to 0.81320, saving model to weights/temp_network.h5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.4988 - acc: 0.8204 - val_loss: 0.5268 - val_acc: 0.8026\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.81320\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.4770 - acc: 0.8283 - val_loss: 0.4918 - val_acc: 0.8253\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.81320 to 0.82530, saving model to weights/temp_network.h5\n",
            "10000/10000 [==============================] - 0s 21us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.8314599981904031\n",
            "Rewards :  0.09461000472307209 Next Reward:  -0.005389995276927916 Accuracy :  0.8253000035881997\n",
            "Total reward :  0.09461000472307209\n",
            "State input to Controller for training :  [0 2]\n",
            "Training RNN (States ip) :  [3, 64, 3, 48, 3, 64, 1, 32]\n",
            "Training RNN (Reward ip) :  [0.09461001]\n",
            "Trial 1: Controller loss : 17.379498\n",
            "\n",
            "Generating random action to explore\n",
            "Actions :\n",
            "******************** Layer 1 ********************\n",
            "kernel :  [(1, 1.0), (3, 0.0)]\n",
            "filters :  [(32, 0.0), (48, 0.0), (64, 3.0)]\n",
            "******************** Layer 2 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 0.0), (48, 0.0), (64, 3.0)]\n",
            "******************** Layer 3 ********************\n",
            "kernel :  [(1, 1.0), (3, 0.0)]\n",
            "filters :  [(32, 0.0), (48, 2.0), (64, 0.0)]\n",
            "******************** Layer 4 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 0.0), (48, 0.0), (64, 3.0)]\n",
            "\n",
            "Predicted actions :  [1, 64, 3, 64, 1, 48, 3, 64]\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 1.2211 - acc: 0.5589 - val_loss: 0.8344 - val_acc: 0.6935\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.69350, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.7538 - acc: 0.7231 - val_loss: 0.7287 - val_acc: 0.7214\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.69350 to 0.72140, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.6845 - acc: 0.7492 - val_loss: 0.6646 - val_acc: 0.7612\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.72140 to 0.76120, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.6344 - acc: 0.7675 - val_loss: 0.6629 - val_acc: 0.7579\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.76120\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.6003 - acc: 0.7793 - val_loss: 0.6113 - val_acc: 0.7747\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.76120 to 0.77470, saving model to weights/temp_network.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.5801 - acc: 0.7887 - val_loss: 0.5811 - val_acc: 0.7860\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.77470 to 0.78600, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.5467 - acc: 0.8023 - val_loss: 0.5557 - val_acc: 0.7968\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.78600 to 0.79680, saving model to weights/temp_network.h5\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.5277 - acc: 0.8096 - val_loss: 0.5489 - val_acc: 0.8092\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.79680 to 0.80920, saving model to weights/temp_network.h5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.5113 - acc: 0.8155 - val_loss: 0.5219 - val_acc: 0.8159\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.80920 to 0.81590, saving model to weights/temp_network.h5\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.4936 - acc: 0.8222 - val_loss: 0.4928 - val_acc: 0.8293\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.81590 to 0.82930, saving model to weights/temp_network.h5\n",
            "10000/10000 [==============================] - 0s 26us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.8310279976129532\n",
            "Rewards :  -0.002160002887249046 Accuracy :  0.829299995303154\n",
            "Generating random action to explore\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 1.4306 - acc: 0.4791 - val_loss: 0.9668 - val_acc: 0.6606\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.66060, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.8767 - acc: 0.6894 - val_loss: 0.8255 - val_acc: 0.6975\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.66060 to 0.69750, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.7687 - acc: 0.7255 - val_loss: 0.7625 - val_acc: 0.7158\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.69750 to 0.71580, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.7192 - acc: 0.7446 - val_loss: 0.7012 - val_acc: 0.7534\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.71580 to 0.75340, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.6804 - acc: 0.7588 - val_loss: 0.6972 - val_acc: 0.7314\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.75340\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.6510 - acc: 0.7694 - val_loss: 0.6456 - val_acc: 0.7690\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.75340 to 0.76900, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.6188 - acc: 0.7817 - val_loss: 0.6436 - val_acc: 0.7780\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.76900 to 0.77800, saving model to weights/temp_network.h5\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.6016 - acc: 0.7873 - val_loss: 0.6118 - val_acc: 0.7823\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.77800 to 0.78230, saving model to weights/temp_network.h5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.5852 - acc: 0.7939 - val_loss: 0.5897 - val_acc: 0.7954\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.78230 to 0.79540, saving model to weights/temp_network.h5\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.5648 - acc: 0.8001 - val_loss: 0.5734 - val_acc: 0.8018\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.79540 to 0.80180, saving model to weights/temp_network.h5\n",
            "10000/10000 [==============================] - 0s 19us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.8251823991179467\n",
            "Rewards :  -0.022619597619772024 Next Reward:  -0.020459594732522977 Accuracy :  0.8018000051379204\n",
            "Total reward :  0.07199040710330007\n",
            "State input to Controller for training :  [1 0]\n",
            "Training RNN (States ip) :  [1, 64, 3, 64, 1, 48, 3, 64]\n",
            "Training RNN (Reward ip) :  [-0.0226196]\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "Trial 2: Controller loss : 15.975427\n",
            "\n",
            "Generating random action to explore\n",
            "Actions :\n",
            "******************** Layer 1 ********************\n",
            "kernel :  [(1, 1.0), (3, 0.0)]\n",
            "filters :  [(32, 1.0), (48, 0.0), (64, 0.0)]\n",
            "******************** Layer 2 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 1.0), (48, 0.0), (64, 0.0)]\n",
            "******************** Layer 3 ********************\n",
            "kernel :  [(1, 1.0), (3, 0.0)]\n",
            "filters :  [(32, 0.0), (48, 0.0), (64, 3.0)]\n",
            "******************** Layer 4 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 0.0), (48, 2.0), (64, 0.0)]\n",
            "\n",
            "Predicted actions :  [1, 32, 3, 32, 1, 64, 3, 48]\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 1.3403 - acc: 0.5234 - val_loss: 0.8653 - val_acc: 0.6939\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.69390, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.8027 - acc: 0.7102 - val_loss: 0.7779 - val_acc: 0.7211\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.69390 to 0.72110, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.7197 - acc: 0.7352 - val_loss: 0.6877 - val_acc: 0.7537\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.72110 to 0.75370, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.6780 - acc: 0.7481 - val_loss: 0.6684 - val_acc: 0.7557\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.75370 to 0.75570, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.6347 - acc: 0.7655 - val_loss: 0.6275 - val_acc: 0.7696\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.75570 to 0.76960, saving model to weights/temp_network.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.6071 - acc: 0.7763 - val_loss: 0.6029 - val_acc: 0.7788\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.76960 to 0.77880, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.5886 - acc: 0.7849 - val_loss: 0.5788 - val_acc: 0.7885\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.77880 to 0.78850, saving model to weights/temp_network.h5\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.5592 - acc: 0.7943 - val_loss: 0.5991 - val_acc: 0.7734\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.78850\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.5421 - acc: 0.8029 - val_loss: 0.5637 - val_acc: 0.7922\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.78850 to 0.79220, saving model to weights/temp_network.h5\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.5234 - acc: 0.8100 - val_loss: 0.5397 - val_acc: 0.8033\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.79220 to 0.80330, saving model to weights/temp_network.h5\n",
            "10000/10000 [==============================] - 0s 18us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.8208059188437462\n",
            "Rewards :  -0.02188240137100228 Accuracy :  0.8032999977469444\n",
            "Prediction action from Controller\n",
            "State input to Controller for Action :  [1. 0.]\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 73us/step - loss: 1.2324 - acc: 0.5549 - val_loss: 0.7998 - val_acc: 0.7049\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.70490, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.7487 - acc: 0.7249 - val_loss: 0.7030 - val_acc: 0.7419\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.70490 to 0.74190, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.6698 - acc: 0.7534 - val_loss: 0.6798 - val_acc: 0.7395\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.74190\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.6220 - acc: 0.7719 - val_loss: 0.6264 - val_acc: 0.7716\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.74190 to 0.77160, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.5894 - acc: 0.7838 - val_loss: 0.5945 - val_acc: 0.7871\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.77160 to 0.78710, saving model to weights/temp_network.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.5596 - acc: 0.7946 - val_loss: 0.5700 - val_acc: 0.7942\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.78710 to 0.79420, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.5343 - acc: 0.8060 - val_loss: 0.5581 - val_acc: 0.8000\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.79420 to 0.80000, saving model to weights/temp_network.h5\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.5122 - acc: 0.8132 - val_loss: 0.5232 - val_acc: 0.8113\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.80000 to 0.81130, saving model to weights/temp_network.h5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.4889 - acc: 0.8214 - val_loss: 0.5055 - val_acc: 0.8204\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.81130 to 0.82040, saving model to weights/temp_network.h5\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.4761 - acc: 0.8262 - val_loss: 0.4898 - val_acc: 0.8266\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.82040 to 0.82660, saving model to weights/temp_network.h5\n",
            "10000/10000 [==============================] - 0s 23us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.8219647339353562\n",
            "Rewards :  -0.017826548550367437 Next Reward:  0.004055852820634842 Accuracy :  0.826599994301796\n",
            "Total reward :  0.05416385855293263\n",
            "State input to Controller for training :  [1 0]\n",
            "Training RNN (States ip) :  [1, 32, 3, 32, 1, 64, 3, 48]\n",
            "Training RNN (Reward ip) :  [-0.01782655]\n",
            "Trial 3: Controller loss : 14.649664\n",
            "\n",
            "Generating random action to explore\n",
            "Actions :\n",
            "******************** Layer 1 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 1.0), (48, 0.0), (64, 0.0)]\n",
            "******************** Layer 2 ********************\n",
            "kernel :  [(1, 1.0), (3, 0.0)]\n",
            "filters :  [(32, 1.0), (48, 0.0), (64, 0.0)]\n",
            "******************** Layer 3 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 1.0), (48, 0.0), (64, 0.0)]\n",
            "******************** Layer 4 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 1.0), (48, 0.0), (64, 0.0)]\n",
            "\n",
            "Predicted actions :  [3, 32, 1, 32, 3, 32, 3, 32]\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 1.2012 - acc: 0.5631 - val_loss: 0.8441 - val_acc: 0.6939\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.69390, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.7381 - acc: 0.7340 - val_loss: 0.7286 - val_acc: 0.7259\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.69390 to 0.72590, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.6587 - acc: 0.7626 - val_loss: 0.6642 - val_acc: 0.7537\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.72590 to 0.75370, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.6037 - acc: 0.7848 - val_loss: 0.5996 - val_acc: 0.7786\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.75370 to 0.77860, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.5575 - acc: 0.8032 - val_loss: 0.5580 - val_acc: 0.8032\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.77860 to 0.80320, saving model to weights/temp_network.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.5227 - acc: 0.8140 - val_loss: 0.5385 - val_acc: 0.8049\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.80320 to 0.80490, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.4965 - acc: 0.8246 - val_loss: 0.5008 - val_acc: 0.8290\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.80490 to 0.82900, saving model to weights/temp_network.h5\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.4779 - acc: 0.8296 - val_loss: 0.4957 - val_acc: 0.8293\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.82900 to 0.82930, saving model to weights/temp_network.h5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.4549 - acc: 0.8387 - val_loss: 0.4643 - val_acc: 0.8432\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.82930 to 0.84320, saving model to weights/temp_network.h5\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.4429 - acc: 0.8425 - val_loss: 0.4781 - val_acc: 0.8328\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.84320\n",
            "10000/10000 [==============================] - 0s 15us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.8262117861803056\n",
            "Rewards :  0.021235261224746615 Accuracy :  0.8431999951601028\n",
            "Generating random action to explore\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 72us/step - loss: 1.2692 - acc: 0.5409 - val_loss: 0.8423 - val_acc: 0.6930\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.69300, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.7726 - acc: 0.7209 - val_loss: 0.7570 - val_acc: 0.7233\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.69300 to 0.72330, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.7029 - acc: 0.7463 - val_loss: 0.6945 - val_acc: 0.7519\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.72330 to 0.75190, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.6516 - acc: 0.7664 - val_loss: 0.6512 - val_acc: 0.7674\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.75190 to 0.76740, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.6114 - acc: 0.7809 - val_loss: 0.6043 - val_acc: 0.7876\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.76740 to 0.78760, saving model to weights/temp_network.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.5877 - acc: 0.7865 - val_loss: 0.5860 - val_acc: 0.7900\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.78760 to 0.79000, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.5577 - acc: 0.7990 - val_loss: 0.5932 - val_acc: 0.7843\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.79000\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.5361 - acc: 0.8070 - val_loss: 0.5390 - val_acc: 0.8093\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.79000 to 0.80930, saving model to weights/temp_network.h5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.5255 - acc: 0.8099 - val_loss: 0.5440 - val_acc: 0.8055\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80930\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.5064 - acc: 0.8164 - val_loss: 0.5369 - val_acc: 0.8043\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80930\n",
            "10000/10000 [==============================] - 0s 20us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.822829428541317\n",
            "Rewards :  0.009397009488286834 Next Reward:  -0.011838251736459781 Accuracy :  0.809299997985363\n",
            "Total reward :  0.06356086804121946\n",
            "State input to Controller for training :  [0 2]\n",
            "Training RNN (States ip) :  [3, 32, 1, 32, 3, 32, 3, 32]\n",
            "Training RNN (Reward ip) :  [0.00939701]\n",
            "Trial 4: Controller loss : 11.138357\n",
            "\n",
            "Generating random action to explore\n",
            "Actions :\n",
            "******************** Layer 1 ********************\n",
            "kernel :  [(1, 1.0), (3, 0.0)]\n",
            "filters :  [(32, 0.0), (48, 2.0), (64, 0.0)]\n",
            "******************** Layer 2 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 0.0), (48, 0.0), (64, 3.0)]\n",
            "******************** Layer 3 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 0.0), (48, 2.0), (64, 0.0)]\n",
            "******************** Layer 4 ********************\n",
            "kernel :  [(1, 1.0), (3, 0.0)]\n",
            "filters :  [(32, 1.0), (48, 0.0), (64, 0.0)]\n",
            "\n",
            "Predicted actions :  [1, 48, 3, 64, 3, 48, 1, 32]\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 1.3977 - acc: 0.4924 - val_loss: 0.9122 - val_acc: 0.6769\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.67690, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.8468 - acc: 0.6958 - val_loss: 0.8000 - val_acc: 0.7105\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.67690 to 0.71050, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.7615 - acc: 0.7242 - val_loss: 0.7361 - val_acc: 0.7392\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.71050 to 0.73920, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.7122 - acc: 0.7419 - val_loss: 0.6871 - val_acc: 0.7545\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.73920 to 0.75450, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.6827 - acc: 0.7534 - val_loss: 0.7101 - val_acc: 0.7522\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.75450\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.6524 - acc: 0.7641 - val_loss: 0.6820 - val_acc: 0.7552\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.75450 to 0.75520, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.6184 - acc: 0.7762 - val_loss: 0.6462 - val_acc: 0.7670\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.75520 to 0.76700, saving model to weights/temp_network.h5\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.5976 - acc: 0.7850 - val_loss: 0.6033 - val_acc: 0.7855\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.76700 to 0.78550, saving model to weights/temp_network.h5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.5803 - acc: 0.7909 - val_loss: 0.6098 - val_acc: 0.7799\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.78550\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.5604 - acc: 0.8003 - val_loss: 0.5877 - val_acc: 0.7921\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.78550 to 0.79210, saving model to weights/temp_network.h5\n",
            "10000/10000 [==============================] - 0s 24us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.8166835429093475\n",
            "Rewards :  -0.03072942815984725 Accuracy :  0.7921000003814698\n",
            "Generating random action to explore\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 1.1459 - acc: 0.5850 - val_loss: 0.7677 - val_acc: 0.7327\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.73270, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.7032 - acc: 0.7434 - val_loss: 0.6640 - val_acc: 0.7568\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.73270 to 0.75680, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.6224 - acc: 0.7733 - val_loss: 0.6001 - val_acc: 0.7758\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.75680 to 0.77580, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.5719 - acc: 0.7932 - val_loss: 0.5592 - val_acc: 0.8038\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.77580 to 0.80380, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.5423 - acc: 0.8056 - val_loss: 0.5586 - val_acc: 0.8008\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80380\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.5150 - acc: 0.8156 - val_loss: 0.5132 - val_acc: 0.8206\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.80380 to 0.82060, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.4914 - acc: 0.8253 - val_loss: 0.5085 - val_acc: 0.8178\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.82060\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.4692 - acc: 0.8335 - val_loss: 0.4786 - val_acc: 0.8293\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.82060 to 0.82930, saving model to weights/temp_network.h5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.4598 - acc: 0.8370 - val_loss: 0.4585 - val_acc: 0.8431\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.82930 to 0.84310, saving model to weights/temp_network.h5\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.4383 - acc: 0.8422 - val_loss: 0.4852 - val_acc: 0.8282\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.84310\n",
            "10000/10000 [==============================] - 0s 21us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.8219668336169907\n",
            "Rewards :  -0.0122379106830963 Next Reward:  0.01849151747675095 Accuracy :  0.8430999964475632\n",
            "Total reward :  0.051322957358123165\n",
            "State input to Controller for training :  [1 0]\n",
            "Training RNN (States ip) :  [1, 48, 3, 64, 3, 48, 1, 32]\n",
            "Training RNN (Reward ip) :  [-0.01223791]\n",
            "Trial 5: Controller loss : 14.363793\n",
            "\n",
            "Generating random action to explore\n",
            "Actions :\n",
            "******************** Layer 1 ********************\n",
            "kernel :  [(1, 1.0), (3, 0.0)]\n",
            "filters :  [(32, 1.0), (48, 0.0), (64, 0.0)]\n",
            "******************** Layer 2 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 0.0), (48, 0.0), (64, 3.0)]\n",
            "******************** Layer 3 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 0.0), (48, 0.0), (64, 3.0)]\n",
            "******************** Layer 4 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 1.0), (48, 0.0), (64, 0.0)]\n",
            "\n",
            "Predicted actions :  [1, 32, 3, 64, 3, 64, 3, 32]\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 1.1735 - acc: 0.5736 - val_loss: 0.8871 - val_acc: 0.6784\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.67840, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.7713 - acc: 0.7201 - val_loss: 0.7362 - val_acc: 0.7232\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.67840 to 0.72320, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.6927 - acc: 0.7481 - val_loss: 0.6881 - val_acc: 0.7550\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.72320 to 0.75500, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.6472 - acc: 0.7629 - val_loss: 0.6245 - val_acc: 0.7696\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.75500 to 0.76960, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.6002 - acc: 0.7815 - val_loss: 0.6300 - val_acc: 0.7567\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.76960\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.5720 - acc: 0.7915 - val_loss: 0.5787 - val_acc: 0.7918\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.76960 to 0.79180, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.5398 - acc: 0.8047 - val_loss: 0.5494 - val_acc: 0.8057\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.79180 to 0.80570, saving model to weights/temp_network.h5\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.5191 - acc: 0.8118 - val_loss: 0.5346 - val_acc: 0.8055\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80570\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.4984 - acc: 0.8194 - val_loss: 0.5326 - val_acc: 0.8078\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.80570 to 0.80780, saving model to weights/temp_network.h5\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.4785 - acc: 0.8249 - val_loss: 0.5014 - val_acc: 0.8150\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.80780 to 0.81500, saving model to weights/temp_network.h5\n",
            "10000/10000 [==============================] - 0s 23us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.8205734667147787\n",
            "Rewards :  -0.0069668345110603935 Accuracy :  0.8149999991059304\n",
            "Generating random action to explore\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 1.0921 - acc: 0.5999 - val_loss: 0.7801 - val_acc: 0.7169\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.71690, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.7291 - acc: 0.7321 - val_loss: 0.7013 - val_acc: 0.7448\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.71690 to 0.74480, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.6513 - acc: 0.7617 - val_loss: 0.6133 - val_acc: 0.7757\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.74480 to 0.77570, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.5921 - acc: 0.7861 - val_loss: 0.6240 - val_acc: 0.7788\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.77570 to 0.77880, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.5511 - acc: 0.8029 - val_loss: 0.5512 - val_acc: 0.8046\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.77880 to 0.80460, saving model to weights/temp_network.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.5182 - acc: 0.8139 - val_loss: 0.5472 - val_acc: 0.7985\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80460\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.4813 - acc: 0.8281 - val_loss: 0.5502 - val_acc: 0.8123\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.80460 to 0.81230, saving model to weights/temp_network.h5\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.4638 - acc: 0.8350 - val_loss: 0.4623 - val_acc: 0.8379\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.81230 to 0.83790, saving model to weights/temp_network.h5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.4474 - acc: 0.8400 - val_loss: 0.4469 - val_acc: 0.8440\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.83790 to 0.84400, saving model to weights/temp_network.h5\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.4298 - acc: 0.8460 - val_loss: 0.4433 - val_acc: 0.8424\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.84400\n",
            "10000/10000 [==============================] - 0s 29us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.8252587739201858\n",
            "Rewards :  0.009431740707864057 Next Reward:  0.01639857521892445 Accuracy :  0.8440000027418136\n",
            "Total reward :  0.060754698065987225\n",
            "State input to Controller for training :  [1 0]\n",
            "Training RNN (States ip) :  [1, 32, 3, 64, 3, 64, 3, 32]\n",
            "Training RNN (Reward ip) :  [0.00943174]\n",
            "Trial 6: Controller loss : 16.098358\n",
            "\n",
            "Generating random action to explore\n",
            "Actions :\n",
            "******************** Layer 1 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 0.0), (48, 2.0), (64, 0.0)]\n",
            "******************** Layer 2 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 1.0), (48, 0.0), (64, 0.0)]\n",
            "******************** Layer 3 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 1.0), (48, 0.0), (64, 0.0)]\n",
            "******************** Layer 4 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 1.0), (48, 0.0), (64, 0.0)]\n",
            "\n",
            "Predicted actions :  [3, 48, 3, 32, 3, 32, 3, 32]\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 1.1361 - acc: 0.5874 - val_loss: 0.7733 - val_acc: 0.7304\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.73040, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.7338 - acc: 0.7361 - val_loss: 0.6935 - val_acc: 0.7492\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.73040 to 0.74920, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.6635 - acc: 0.7596 - val_loss: 0.7160 - val_acc: 0.7360\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.74920\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.6163 - acc: 0.7774 - val_loss: 0.5818 - val_acc: 0.7946\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.74920 to 0.79460, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.5852 - acc: 0.7910 - val_loss: 0.5784 - val_acc: 0.7959\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.79460 to 0.79590, saving model to weights/temp_network.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.5347 - acc: 0.8085 - val_loss: 0.5535 - val_acc: 0.8072\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.79590 to 0.80720, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.5143 - acc: 0.8143 - val_loss: 0.5348 - val_acc: 0.8044\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80720\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.4905 - acc: 0.8238 - val_loss: 0.4887 - val_acc: 0.8262\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.80720 to 0.82620, saving model to weights/temp_network.h5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.4678 - acc: 0.8325 - val_loss: 0.4851 - val_acc: 0.8279\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.82620 to 0.82790, saving model to weights/temp_network.h5\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.4476 - acc: 0.8413 - val_loss: 0.4567 - val_acc: 0.8422\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.82790 to 0.84220, saving model to weights/temp_network.h5\n",
            "10000/10000 [==============================] - 0s 19us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.828647019550997\n",
            "Rewards :  0.016941228154055854 Accuracy :  0.8422000020742416\n",
            "Generating random action to explore\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 1.1698 - acc: 0.5793 - val_loss: 0.8416 - val_acc: 0.6976\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.69760, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.7529 - acc: 0.7280 - val_loss: 0.7117 - val_acc: 0.7460\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.69760 to 0.74600, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.6741 - acc: 0.7554 - val_loss: 0.6639 - val_acc: 0.7637\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.74600 to 0.76370, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.6257 - acc: 0.7742 - val_loss: 0.6136 - val_acc: 0.7781\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.76370 to 0.77810, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.5846 - acc: 0.7906 - val_loss: 0.5716 - val_acc: 0.7949\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.77810 to 0.79490, saving model to weights/temp_network.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.5572 - acc: 0.8002 - val_loss: 0.5448 - val_acc: 0.8081\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.79490 to 0.80810, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.5236 - acc: 0.8110 - val_loss: 0.5414 - val_acc: 0.8044\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80810\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.5065 - acc: 0.8178 - val_loss: 0.5083 - val_acc: 0.8186\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.80810 to 0.81860, saving model to weights/temp_network.h5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.4824 - acc: 0.8256 - val_loss: 0.4827 - val_acc: 0.8302\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.81860 to 0.83020, saving model to weights/temp_network.h5\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.4617 - acc: 0.8344 - val_loss: 0.4733 - val_acc: 0.8318\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.83020 to 0.83180, saving model to weights/temp_network.h5\n",
            "10000/10000 [==============================] - 0s 24us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.8292776163107538\n",
            "Rewards :  0.01914831681320468 Next Reward:  0.0022070886591488256 Accuracy :  0.831800003349781\n",
            "Total reward :  0.07990301487919191\n",
            "State input to Controller for training :  [0 2]\n",
            "Training RNN (States ip) :  [3, 48, 3, 32, 3, 32, 3, 32]\n",
            "Training RNN (Reward ip) :  [0.01914832]\n",
            "Trial 7: Controller loss : 12.456779\n",
            "\n",
            "Generating random action to explore\n",
            "Actions :\n",
            "******************** Layer 1 ********************\n",
            "kernel :  [(1, 1.0), (3, 0.0)]\n",
            "filters :  [(32, 0.0), (48, 2.0), (64, 0.0)]\n",
            "******************** Layer 2 ********************\n",
            "kernel :  [(1, 1.0), (3, 0.0)]\n",
            "filters :  [(32, 1.0), (48, 0.0), (64, 0.0)]\n",
            "******************** Layer 3 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 1.0), (48, 0.0), (64, 0.0)]\n",
            "******************** Layer 4 ********************\n",
            "kernel :  [(1, 1.0), (3, 0.0)]\n",
            "filters :  [(32, 0.0), (48, 0.0), (64, 3.0)]\n",
            "\n",
            "Predicted actions :  [1, 48, 1, 32, 3, 32, 1, 64]\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 1.6889 - acc: 0.3754 - val_loss: 1.1056 - val_acc: 0.5934\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.59340, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.9851 - acc: 0.6519 - val_loss: 0.9140 - val_acc: 0.6859\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.59340 to 0.68590, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.8605 - acc: 0.6951 - val_loss: 0.8395 - val_acc: 0.7002\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.68590 to 0.70020, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.7987 - acc: 0.7168 - val_loss: 0.7941 - val_acc: 0.7127\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.70020 to 0.71270, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.7628 - acc: 0.7276 - val_loss: 0.7535 - val_acc: 0.7325\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.71270 to 0.73250, saving model to weights/temp_network.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.7348 - acc: 0.7377 - val_loss: 0.7385 - val_acc: 0.7327\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.73250 to 0.73270, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.7091 - acc: 0.7461 - val_loss: 0.7198 - val_acc: 0.7464\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.73270 to 0.74640, saving model to weights/temp_network.h5\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.6908 - acc: 0.7539 - val_loss: 0.6969 - val_acc: 0.7511\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.74640 to 0.75110, saving model to weights/temp_network.h5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.6731 - acc: 0.7581 - val_loss: 0.6802 - val_acc: 0.7540\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.75110 to 0.75400, saving model to weights/temp_network.h5\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 0.6587 - acc: 0.7640 - val_loss: 0.6798 - val_acc: 0.7579\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.75400 to 0.75790, saving model to weights/temp_network.h5\n",
            "10000/10000 [==============================] - 0s 15us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.8150020929723092\n",
            "Rewards :  -0.07137761669222353 Accuracy :  0.7578999996185303\n",
            "Generating random action to explore\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 1.3388 - acc: 0.5223 - val_loss: 0.8984 - val_acc: 0.6893\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.68930, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.8058 - acc: 0.7117 - val_loss: 0.7663 - val_acc: 0.7281\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.68930 to 0.72810, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.7395 - acc: 0.7365 - val_loss: 0.7486 - val_acc: 0.7350\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.72810 to 0.73500, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.7016 - acc: 0.7522 - val_loss: 0.7242 - val_acc: 0.7509\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.73500 to 0.75090, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.6748 - acc: 0.7592 - val_loss: 0.6706 - val_acc: 0.7639\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.75090 to 0.76390, saving model to weights/temp_network.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.6465 - acc: 0.7703 - val_loss: 0.6438 - val_acc: 0.7654\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.76390 to 0.76540, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.6265 - acc: 0.7771 - val_loss: 0.6402 - val_acc: 0.7670\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.76540 to 0.76700, saving model to weights/temp_network.h5\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.6059 - acc: 0.7838 - val_loss: 0.6110 - val_acc: 0.7776\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.76700 to 0.77760, saving model to weights/temp_network.h5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.5818 - acc: 0.7927 - val_loss: 0.6157 - val_acc: 0.7769\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.77760\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.5687 - acc: 0.7981 - val_loss: 0.5717 - val_acc: 0.7955\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.77760 to 0.79550, saving model to weights/temp_network.h5\n",
            "10000/10000 [==============================] - 0s 14us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.8111016740440613\n",
            "Rewards :  -0.08502908294109097 Next Reward:  -0.013651466248867438 Accuracy :  0.79549999833107\n",
            "Total reward :  -0.005126068061899067\n",
            "State input to Controller for training :  [1 0]\n",
            "Training RNN (States ip) :  [1, 48, 1, 32, 3, 32, 1, 64]\n",
            "Training RNN (Reward ip) :  [-0.08502908]\n",
            "Trial 8: Controller loss : 11.716852\n",
            "\n",
            "Generating random action to explore\n",
            "Actions :\n",
            "******************** Layer 1 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 0.0), (48, 2.0), (64, 0.0)]\n",
            "******************** Layer 2 ********************\n",
            "kernel :  [(1, 1.0), (3, 0.0)]\n",
            "filters :  [(32, 0.0), (48, 0.0), (64, 3.0)]\n",
            "******************** Layer 3 ********************\n",
            "kernel :  [(1, 1.0), (3, 0.0)]\n",
            "filters :  [(32, 0.0), (48, 2.0), (64, 0.0)]\n",
            "******************** Layer 4 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 0.0), (48, 2.0), (64, 0.0)]\n",
            "\n",
            "Predicted actions :  [3, 48, 1, 64, 1, 48, 3, 48]\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 1.2909 - acc: 0.5422 - val_loss: 0.8593 - val_acc: 0.6976\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.69760, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.7758 - acc: 0.7227 - val_loss: 0.7161 - val_acc: 0.7446\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.69760 to 0.74460, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.6876 - acc: 0.7530 - val_loss: 0.6390 - val_acc: 0.7757\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.74460 to 0.77570, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.6291 - acc: 0.7717 - val_loss: 0.6458 - val_acc: 0.7506\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.77570\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.5891 - acc: 0.7888 - val_loss: 0.6014 - val_acc: 0.7822\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.77570 to 0.78220, saving model to weights/temp_network.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.5688 - acc: 0.7954 - val_loss: 0.5708 - val_acc: 0.8001\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.78220 to 0.80010, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.5455 - acc: 0.8052 - val_loss: 0.5440 - val_acc: 0.8086\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.80010 to 0.80860, saving model to weights/temp_network.h5\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.5332 - acc: 0.8085 - val_loss: 0.5313 - val_acc: 0.8098\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.80860 to 0.80980, saving model to weights/temp_network.h5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.5179 - acc: 0.8144 - val_loss: 0.5249 - val_acc: 0.8154\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.80980 to 0.81540, saving model to weights/temp_network.h5\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.5082 - acc: 0.8171 - val_loss: 0.5256 - val_acc: 0.8090\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.81540\n",
            "10000/10000 [==============================] - 0s 20us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.8119613398146062\n",
            "Rewards :  0.004298328852724409 Accuracy :  0.8154000028967857\n",
            "Prediction action from Controller\n",
            "State input to Controller for Action :  [1. 0.]\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 1.1724 - acc: 0.5751 - val_loss: 0.7871 - val_acc: 0.7093\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.70930, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 4s 69us/step - loss: 0.7229 - acc: 0.7393 - val_loss: 0.6903 - val_acc: 0.7557\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.70930 to 0.75570, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 4s 69us/step - loss: 0.6538 - acc: 0.7649 - val_loss: 0.6263 - val_acc: 0.7787\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.75570 to 0.77870, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 4s 69us/step - loss: 0.5965 - acc: 0.7872 - val_loss: 0.6118 - val_acc: 0.7847\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.77870 to 0.78470, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 0.5626 - acc: 0.7980 - val_loss: 0.5603 - val_acc: 0.8009\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.78470 to 0.80090, saving model to weights/temp_network.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 4s 69us/step - loss: 0.5324 - acc: 0.8084 - val_loss: 0.5416 - val_acc: 0.8035\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.80090 to 0.80350, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.5097 - acc: 0.8180 - val_loss: 0.5123 - val_acc: 0.8171\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.80350 to 0.81710, saving model to weights/temp_network.h5\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 0.4890 - acc: 0.8234 - val_loss: 0.5023 - val_acc: 0.8203\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.81710 to 0.82030, saving model to weights/temp_network.h5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 4s 69us/step - loss: 0.4706 - acc: 0.8301 - val_loss: 0.5212 - val_acc: 0.8101\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.82030\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 4s 69us/step - loss: 0.4555 - acc: 0.8362 - val_loss: 0.4876 - val_acc: 0.8189\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.82030\n",
            "10000/10000 [==============================] - 0s 23us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.8136290717348599\n",
            "Rewards :  0.010135390573612246 Next Reward:  0.0058370617208878366 Accuracy :  0.8202999994158745\n",
            "Total reward :  0.005009322511713179\n",
            "State input to Controller for training :  [0 2]\n",
            "Training RNN (States ip) :  [3, 48, 1, 64, 1, 48, 3, 48]\n",
            "Training RNN (Reward ip) :  [0.01013539]\n",
            "Trial 9: Controller loss : 15.837552\n",
            "\n",
            "Generating random action to explore\n",
            "Actions :\n",
            "******************** Layer 1 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 1.0), (48, 0.0), (64, 0.0)]\n",
            "******************** Layer 2 ********************\n",
            "kernel :  [(1, 1.0), (3, 0.0)]\n",
            "filters :  [(32, 1.0), (48, 0.0), (64, 0.0)]\n",
            "******************** Layer 3 ********************\n",
            "kernel :  [(1, 1.0), (3, 0.0)]\n",
            "filters :  [(32, 0.0), (48, 0.0), (64, 3.0)]\n",
            "******************** Layer 4 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 1.0), (48, 0.0), (64, 0.0)]\n",
            "\n",
            "Predicted actions :  [3, 32, 1, 32, 1, 64, 3, 32]\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 51us/step - loss: 1.3137 - acc: 0.5187 - val_loss: 0.9362 - val_acc: 0.6579\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.65790, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.8312 - acc: 0.7003 - val_loss: 0.7978 - val_acc: 0.7036\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.65790 to 0.70360, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.7536 - acc: 0.7263 - val_loss: 0.7318 - val_acc: 0.7304\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.70360 to 0.73040, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.7060 - acc: 0.7476 - val_loss: 0.6970 - val_acc: 0.7515\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.73040 to 0.75150, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.6713 - acc: 0.7585 - val_loss: 0.6725 - val_acc: 0.7586\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.75150 to 0.75860, saving model to weights/temp_network.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.6435 - acc: 0.7707 - val_loss: 0.6371 - val_acc: 0.7730\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.75860 to 0.77300, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.6153 - acc: 0.7790 - val_loss: 0.6149 - val_acc: 0.7809\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.77300 to 0.78090, saving model to weights/temp_network.h5\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.6013 - acc: 0.7847 - val_loss: 0.6094 - val_acc: 0.7802\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.78090\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.5797 - acc: 0.7923 - val_loss: 0.5825 - val_acc: 0.7972\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.78090 to 0.79720, saving model to weights/temp_network.h5\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.5688 - acc: 0.7958 - val_loss: 0.5686 - val_acc: 0.8015\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.79720 to 0.80150, saving model to weights/temp_network.h5\n",
            "10000/10000 [==============================] - 0s 14us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.8112032571017855\n",
            "Rewards :  -0.012129073165371373 Accuracy :  0.8014999985694885\n",
            "Generating random action to explore\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 1.3066 - acc: 0.5276 - val_loss: 0.9382 - val_acc: 0.6715\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.67150, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 4s 58us/step - loss: 0.8605 - acc: 0.6911 - val_loss: 0.8452 - val_acc: 0.6911\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.67150 to 0.69110, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.7646 - acc: 0.7220 - val_loss: 0.7261 - val_acc: 0.7422\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.69110 to 0.74220, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.7086 - acc: 0.7418 - val_loss: 0.6905 - val_acc: 0.7387\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.74220\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.6595 - acc: 0.7612 - val_loss: 0.6751 - val_acc: 0.7433\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.74220 to 0.74330, saving model to weights/temp_network.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.6320 - acc: 0.7695 - val_loss: 0.6305 - val_acc: 0.7601\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.74330 to 0.76010, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.5940 - acc: 0.7861 - val_loss: 0.6007 - val_acc: 0.7824\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.76010 to 0.78240, saving model to weights/temp_network.h5\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.5652 - acc: 0.7978 - val_loss: 0.5605 - val_acc: 0.8029\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.78240 to 0.80290, saving model to weights/temp_network.h5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.5514 - acc: 0.8016 - val_loss: 0.5828 - val_acc: 0.7932\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80290\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 4s 58us/step - loss: 0.5222 - acc: 0.8136 - val_loss: 0.5355 - val_acc: 0.8095\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.80290 to 0.80950, saving model to weights/temp_network.h5\n",
            "10000/10000 [==============================] - 0s 19us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.8108626053595633\n",
            "Rewards :  -0.013321354263149066 Next Reward:  -0.001192281097777692 Accuracy :  0.8094999983906745\n",
            "Total reward :  -0.008312031751435887\n",
            "State input to Controller for training :  [0 2]\n",
            "Training RNN (States ip) :  [3, 32, 1, 32, 1, 64, 3, 32]\n",
            "Training RNN (Reward ip) :  [-0.01332135]\n",
            "Trial 10: Controller loss : 12.640358\n",
            "\n",
            "Generating random action to explore\n",
            "Actions :\n",
            "******************** Layer 1 ********************\n",
            "kernel :  [(1, 1.0), (3, 0.0)]\n",
            "filters :  [(32, 0.0), (48, 2.0), (64, 0.0)]\n",
            "******************** Layer 2 ********************\n",
            "kernel :  [(1, 1.0), (3, 0.0)]\n",
            "filters :  [(32, 0.0), (48, 0.0), (64, 3.0)]\n",
            "******************** Layer 3 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 0.0), (48, 2.0), (64, 0.0)]\n",
            "******************** Layer 4 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 0.0), (48, 0.0), (64, 3.0)]\n",
            "\n",
            "Predicted actions :  [1, 48, 1, 64, 3, 48, 3, 64]\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 1.1725 - acc: 0.5686 - val_loss: 0.7877 - val_acc: 0.7030\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.70300, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 4s 72us/step - loss: 0.7139 - acc: 0.7399 - val_loss: 0.6940 - val_acc: 0.7393\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.70300 to 0.73930, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 0.6391 - acc: 0.7671 - val_loss: 0.6088 - val_acc: 0.7833\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.73930 to 0.78330, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 0.5911 - acc: 0.7868 - val_loss: 0.5856 - val_acc: 0.7900\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.78330 to 0.79000, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 0.5532 - acc: 0.8003 - val_loss: 0.5565 - val_acc: 0.8040\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.79000 to 0.80400, saving model to weights/temp_network.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 4s 72us/step - loss: 0.5238 - acc: 0.8111 - val_loss: 0.5273 - val_acc: 0.8152\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.80400 to 0.81520, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 4s 73us/step - loss: 0.4986 - acc: 0.8211 - val_loss: 0.5273 - val_acc: 0.8069\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.81520\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 4s 72us/step - loss: 0.4741 - acc: 0.8306 - val_loss: 0.4849 - val_acc: 0.8241\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.81520 to 0.82410, saving model to weights/temp_network.h5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 4s 72us/step - loss: 0.4534 - acc: 0.8375 - val_loss: 0.4812 - val_acc: 0.8288\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.82410 to 0.82880, saving model to weights/temp_network.h5\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 4s 72us/step - loss: 0.4416 - acc: 0.8407 - val_loss: 0.4456 - val_acc: 0.8418\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.82880 to 0.84180, saving model to weights/temp_network.h5\n",
            "10000/10000 [==============================] - 0s 23us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.8170500836463047\n",
            "Rewards :  0.030937391433706773 Accuracy :  0.8417999967932701\n",
            "Generating random action to explore\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 1.3377 - acc: 0.5166 - val_loss: 0.8774 - val_acc: 0.6837\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.68370, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.8103 - acc: 0.7069 - val_loss: 0.7844 - val_acc: 0.7175\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.68370 to 0.71750, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.7540 - acc: 0.7234 - val_loss: 0.7771 - val_acc: 0.6987\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.71750\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.7023 - acc: 0.7439 - val_loss: 0.6813 - val_acc: 0.7567\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.71750 to 0.75670, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.6693 - acc: 0.7517 - val_loss: 0.6544 - val_acc: 0.7615\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.75670 to 0.76150, saving model to weights/temp_network.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.6431 - acc: 0.7620 - val_loss: 0.6446 - val_acc: 0.7607\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.76150\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.6245 - acc: 0.7666 - val_loss: 0.6225 - val_acc: 0.7731\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.76150 to 0.77310, saving model to weights/temp_network.h5\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.6058 - acc: 0.7748 - val_loss: 0.6074 - val_acc: 0.7794\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.77310 to 0.77940, saving model to weights/temp_network.h5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.5898 - acc: 0.7814 - val_loss: 0.6289 - val_acc: 0.7710\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.77940\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.5762 - acc: 0.7849 - val_loss: 0.6081 - val_acc: 0.7735\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.77940\n",
            "10000/10000 [==============================] - 0s 18us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.809520066316229\n",
            "Rewards :  0.0045823307784415915 Next Reward:  -0.026355060655265182 Accuracy :  0.7793999969959259\n",
            "Total reward :  -0.0037297009729942952\n",
            "State input to Controller for training :  [1 0]\n",
            "Training RNN (States ip) :  [1, 48, 1, 64, 3, 48, 3, 64]\n",
            "Training RNN (Reward ip) :  [0.00458233]\n",
            "Trial 11: Controller loss : 15.680357\n",
            "\n",
            "Generating random action to explore\n",
            "Actions :\n",
            "******************** Layer 1 ********************\n",
            "kernel :  [(1, 1.0), (3, 0.0)]\n",
            "filters :  [(32, 0.0), (48, 0.0), (64, 3.0)]\n",
            "******************** Layer 2 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 0.0), (48, 0.0), (64, 3.0)]\n",
            "******************** Layer 3 ********************\n",
            "kernel :  [(1, 1.0), (3, 0.0)]\n",
            "filters :  [(32, 0.0), (48, 0.0), (64, 3.0)]\n",
            "******************** Layer 4 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 1.0), (48, 0.0), (64, 0.0)]\n",
            "\n",
            "Predicted actions :  [1, 64, 3, 64, 1, 64, 3, 32]\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 1.3218 - acc: 0.5240 - val_loss: 0.9426 - val_acc: 0.6579\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.65790, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.8254 - acc: 0.7056 - val_loss: 0.7786 - val_acc: 0.7125\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.65790 to 0.71250, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.7360 - acc: 0.7323 - val_loss: 0.7755 - val_acc: 0.7321\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.71250 to 0.73210, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.6923 - acc: 0.7470 - val_loss: 0.6931 - val_acc: 0.7360\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.73210 to 0.73600, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.6486 - acc: 0.7620 - val_loss: 0.6460 - val_acc: 0.7661\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.73600 to 0.76610, saving model to weights/temp_network.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.6183 - acc: 0.7755 - val_loss: 0.6506 - val_acc: 0.7506\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.76610\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.5977 - acc: 0.7809 - val_loss: 0.6558 - val_acc: 0.7531\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.76610\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.5757 - acc: 0.7917 - val_loss: 0.6046 - val_acc: 0.7809\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.76610 to 0.78090, saving model to weights/temp_network.h5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.5609 - acc: 0.7957 - val_loss: 0.5666 - val_acc: 0.7930\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.78090 to 0.79300, saving model to weights/temp_network.h5\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.5484 - acc: 0.8006 - val_loss: 0.5712 - val_acc: 0.7921\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.79300\n",
            "10000/10000 [==============================] - 0s 24us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.8062160528980111\n",
            "Rewards :  -0.01652006709108933 Accuracy :  0.7929999992251396\n",
            "Generating random action to explore\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 1.1066 - acc: 0.5909 - val_loss: 0.7865 - val_acc: 0.6974\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.69740, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.7097 - acc: 0.7385 - val_loss: 0.7321 - val_acc: 0.7283\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.69740 to 0.72830, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.6538 - acc: 0.7603 - val_loss: 0.6400 - val_acc: 0.7677\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.72830 to 0.76770, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.5992 - acc: 0.7833 - val_loss: 0.6177 - val_acc: 0.7800\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.76770 to 0.78000, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.5569 - acc: 0.8001 - val_loss: 0.5457 - val_acc: 0.8081\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.78000 to 0.80810, saving model to weights/temp_network.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.5228 - acc: 0.8131 - val_loss: 0.5241 - val_acc: 0.8170\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.80810 to 0.81700, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.4972 - acc: 0.8233 - val_loss: 0.4848 - val_acc: 0.8287\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.81700 to 0.82870, saving model to weights/temp_network.h5\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.4761 - acc: 0.8282 - val_loss: 0.4945 - val_acc: 0.8263\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.82870\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.4531 - acc: 0.8366 - val_loss: 0.4676 - val_acc: 0.8397\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.82870 to 0.83970, saving model to weights/temp_network.h5\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.4446 - acc: 0.8398 - val_loss: 0.4684 - val_acc: 0.8285\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.83970\n",
            "10000/10000 [==============================] - 0s 22us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.812912841421955\n",
            "Rewards :  0.006918692742714349 Next Reward:  0.02343875983380368 Accuracy :  0.8396999955177307\n",
            "Total reward :  0.0031889917697200537\n",
            "State input to Controller for training :  [1 0]\n",
            "Training RNN (States ip) :  [1, 64, 3, 64, 1, 64, 3, 32]\n",
            "Training RNN (Reward ip) :  [0.00691869]\n",
            "Trial 12: Controller loss : 17.342388\n",
            "\n",
            "Prediction action from Controller\n",
            "State input to Controller for Action :  [1. 0.]\n",
            "Actions :\n",
            "******************** Layer 1 ********************\n",
            "kernel :  [(1, 0.52795637), (3, 0.47204366)]\n",
            "filters :  [(32, 0.25638297), (48, 0.3666732), (64, 0.3769438)]\n",
            "******************** Layer 2 ********************\n",
            "kernel :  [(1, 0.5129764), (3, 0.48702362)]\n",
            "filters :  [(32, 0.28349686), (48, 0.4801709), (64, 0.2363322)]\n",
            "******************** Layer 3 ********************\n",
            "kernel :  [(1, 0.46284592), (3, 0.537154)]\n",
            "filters :  [(32, 0.2413027), (48, 0.46380565), (64, 0.29489166)]\n",
            "******************** Layer 4 ********************\n",
            "kernel :  [(1, 0.32860908), (3, 0.67139095)]\n",
            "filters :  [(32, 0.33203524), (48, 0.27774084), (64, 0.39022392)]\n",
            "\n",
            "Predicted actions :  [1, 64, 1, 48, 3, 48, 3, 64]\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 1.1969 - acc: 0.5705 - val_loss: 0.7875 - val_acc: 0.7163\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.71630, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 4s 69us/step - loss: 0.7209 - acc: 0.7381 - val_loss: 0.7493 - val_acc: 0.7317\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.71630 to 0.73170, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 4s 69us/step - loss: 0.6477 - acc: 0.7648 - val_loss: 0.6264 - val_acc: 0.7755\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.73170 to 0.77550, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.6008 - acc: 0.7831 - val_loss: 0.6033 - val_acc: 0.7772\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.77550 to 0.77720, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.5652 - acc: 0.7953 - val_loss: 0.5731 - val_acc: 0.7914\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.77720 to 0.79140, saving model to weights/temp_network.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 4s 69us/step - loss: 0.5406 - acc: 0.8032 - val_loss: 0.5824 - val_acc: 0.7831\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.79140\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.5183 - acc: 0.8118 - val_loss: 0.5212 - val_acc: 0.8093\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.79140 to 0.80930, saving model to weights/temp_network.h5\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 4s 69us/step - loss: 0.4979 - acc: 0.8186 - val_loss: 0.5111 - val_acc: 0.8152\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.80930 to 0.81520, saving model to weights/temp_network.h5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.4814 - acc: 0.8255 - val_loss: 0.5272 - val_acc: 0.8075\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.81520\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 4s 69us/step - loss: 0.4647 - acc: 0.8318 - val_loss: 0.5033 - val_acc: 0.8201\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.81520 to 0.82010, saving model to weights/temp_network.h5\n",
            "10000/10000 [==============================] - 0s 22us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.8143502729396765\n",
            "Rewards :  0.007187157588607884 Accuracy :  0.8200999990105629\n",
            "Generating random action to explore\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 1.3332 - acc: 0.5146 - val_loss: 0.8806 - val_acc: 0.6807\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.68070, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 51us/step - loss: 0.7968 - acc: 0.7095 - val_loss: 0.7783 - val_acc: 0.7182\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.68070 to 0.71820, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 51us/step - loss: 0.7207 - acc: 0.7361 - val_loss: 0.7240 - val_acc: 0.7248\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.71820 to 0.72480, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 50us/step - loss: 0.6736 - acc: 0.7554 - val_loss: 0.6581 - val_acc: 0.7629\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.72480 to 0.76290, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 51us/step - loss: 0.6433 - acc: 0.7668 - val_loss: 0.6754 - val_acc: 0.7628\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.76290\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 51us/step - loss: 0.6232 - acc: 0.7752 - val_loss: 0.6340 - val_acc: 0.7710\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.76290 to 0.77100, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 51us/step - loss: 0.5923 - acc: 0.7885 - val_loss: 0.5956 - val_acc: 0.7896\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.77100 to 0.78960, saving model to weights/temp_network.h5\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 0.5736 - acc: 0.7976 - val_loss: 0.6000 - val_acc: 0.7836\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.78960\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 0.5606 - acc: 0.8017 - val_loss: 0.5569 - val_acc: 0.8079\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.78960 to 0.80790, saving model to weights/temp_network.h5\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 0.5447 - acc: 0.8087 - val_loss: 0.5719 - val_acc: 0.7944\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80790\n",
            "10000/10000 [==============================] - 0s 16us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.8130602182754474\n",
            "Rewards :  0.0026719662638055256 Next Reward:  -0.004515191324802359 Accuracy :  0.8078999996185303\n",
            "Total reward :  0.005860958033525579\n",
            "State input to Controller for training :  [0 0]\n",
            "Training RNN (States ip) :  [1, 64, 1, 48, 3, 48, 3, 64]\n",
            "Training RNN (Reward ip) :  [0.00267197]\n",
            "Trial 13: Controller loss : 13.611130\n",
            "\n",
            "Generating random action to explore\n",
            "Actions :\n",
            "******************** Layer 1 ********************\n",
            "kernel :  [(1, 1.0), (3, 0.0)]\n",
            "filters :  [(32, 0.0), (48, 2.0), (64, 0.0)]\n",
            "******************** Layer 2 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 1.0), (48, 0.0), (64, 0.0)]\n",
            "******************** Layer 3 ********************\n",
            "kernel :  [(1, 1.0), (3, 0.0)]\n",
            "filters :  [(32, 0.0), (48, 2.0), (64, 0.0)]\n",
            "******************** Layer 4 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 0.0), (48, 2.0), (64, 0.0)]\n",
            "\n",
            "Predicted actions :  [1, 48, 3, 32, 1, 48, 3, 48]\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 1.2940 - acc: 0.5414 - val_loss: 0.8542 - val_acc: 0.7022\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.70220, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.7854 - acc: 0.7151 - val_loss: 0.7559 - val_acc: 0.7265\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.70220 to 0.72650, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.7107 - acc: 0.7392 - val_loss: 0.6783 - val_acc: 0.7564\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.72650 to 0.75640, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.6688 - acc: 0.7572 - val_loss: 0.6677 - val_acc: 0.7581\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.75640 to 0.75810, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.6391 - acc: 0.7663 - val_loss: 0.6637 - val_acc: 0.7468\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.75810\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.6163 - acc: 0.7742 - val_loss: 0.6414 - val_acc: 0.7554\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.75810\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.5910 - acc: 0.7859 - val_loss: 0.6177 - val_acc: 0.7751\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.75810 to 0.77510, saving model to weights/temp_network.h5\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.5744 - acc: 0.7899 - val_loss: 0.5914 - val_acc: 0.7882\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.77510 to 0.78820, saving model to weights/temp_network.h5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.5619 - acc: 0.7943 - val_loss: 0.5560 - val_acc: 0.7957\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.78820 to 0.79570, saving model to weights/temp_network.h5\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.5422 - acc: 0.8016 - val_loss: 0.5551 - val_acc: 0.8038\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.79570 to 0.80380, saving model to weights/temp_network.h5\n",
            "10000/10000 [==============================] - 0s 19us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.8112081755644955\n",
            "Rewards :  -0.009260213554759478 Accuracy :  0.8038000047206879\n",
            "Generating random action to explore\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 73us/step - loss: 1.3885 - acc: 0.4887 - val_loss: 0.9192 - val_acc: 0.6912\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.69120, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.8406 - acc: 0.7057 - val_loss: 0.7780 - val_acc: 0.7225\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.69120 to 0.72250, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.7425 - acc: 0.7368 - val_loss: 0.7093 - val_acc: 0.7513\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.72250 to 0.75130, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.6914 - acc: 0.7531 - val_loss: 0.6666 - val_acc: 0.7653\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.75130 to 0.76530, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.6572 - acc: 0.7650 - val_loss: 0.6860 - val_acc: 0.7500\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.76530\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.6248 - acc: 0.7774 - val_loss: 0.6148 - val_acc: 0.7852\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.76530 to 0.78520, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.5979 - acc: 0.7872 - val_loss: 0.6009 - val_acc: 0.7871\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.78520 to 0.78710, saving model to weights/temp_network.h5\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.5780 - acc: 0.7956 - val_loss: 0.5779 - val_acc: 0.7984\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.78710 to 0.79840, saving model to weights/temp_network.h5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.5554 - acc: 0.8035 - val_loss: 0.5553 - val_acc: 0.8057\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.79840 to 0.80570, saving model to weights/temp_network.h5\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.5423 - acc: 0.8082 - val_loss: 0.5521 - val_acc: 0.8026\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80570\n",
            "10000/10000 [==============================] - 0s 20us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.8101065403776867\n",
            "Rewards :  -0.013115936708590481 Next Reward:  -0.003855723153831003 Accuracy :  0.8056999996304512\n",
            "Total reward :  -0.007254978675064902\n",
            "State input to Controller for training :  [1 0]\n",
            "Training RNN (States ip) :  [1, 48, 3, 32, 1, 48, 3, 48]\n",
            "Training RNN (Reward ip) :  [-0.01311594]\n",
            "Trial 14: Controller loss : 12.547240\n",
            "\n",
            "Generating random action to explore\n",
            "Actions :\n",
            "******************** Layer 1 ********************\n",
            "kernel :  [(1, 1.0), (3, 0.0)]\n",
            "filters :  [(32, 0.0), (48, 2.0), (64, 0.0)]\n",
            "******************** Layer 2 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 1.0), (48, 0.0), (64, 0.0)]\n",
            "******************** Layer 3 ********************\n",
            "kernel :  [(1, 1.0), (3, 0.0)]\n",
            "filters :  [(32, 1.0), (48, 0.0), (64, 0.0)]\n",
            "******************** Layer 4 ********************\n",
            "kernel :  [(1, 1.0), (3, 0.0)]\n",
            "filters :  [(32, 1.0), (48, 0.0), (64, 0.0)]\n",
            "\n",
            "Predicted actions :  [1, 48, 3, 32, 1, 32, 1, 32]\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 1.7206 - acc: 0.3764 - val_loss: 1.2751 - val_acc: 0.5427\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.54270, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 1.1847 - acc: 0.5689 - val_loss: 1.1226 - val_acc: 0.5862\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.54270 to 0.58620, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 1.0739 - acc: 0.6073 - val_loss: 1.0370 - val_acc: 0.6082\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.58620 to 0.60820, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 1.0032 - acc: 0.6284 - val_loss: 0.9891 - val_acc: 0.6296\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.60820 to 0.62960, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.9412 - acc: 0.6513 - val_loss: 0.9226 - val_acc: 0.6652\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.62960 to 0.66520, saving model to weights/temp_network.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.8910 - acc: 0.6732 - val_loss: 0.8761 - val_acc: 0.6802\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.66520 to 0.68020, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.8544 - acc: 0.6888 - val_loss: 0.8559 - val_acc: 0.6889\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.68020 to 0.68890, saving model to weights/temp_network.h5\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.8241 - acc: 0.7008 - val_loss: 0.8200 - val_acc: 0.7055\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.68890 to 0.70550, saving model to weights/temp_network.h5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.8057 - acc: 0.7104 - val_loss: 0.8005 - val_acc: 0.7100\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.70550 to 0.71000, saving model to weights/temp_network.h5\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.7840 - acc: 0.7196 - val_loss: 0.7842 - val_acc: 0.7178\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.71000 to 0.71780, saving model to weights/temp_network.h5\n",
            "10000/10000 [==============================] - 0s 16us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.7916452323641382\n",
            "Rewards :  -0.09230654006774253 Accuracy :  0.7178000003099442\n",
            "Generating random action to explore\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 1.7038 - acc: 0.3852 - val_loss: 1.1892 - val_acc: 0.5533\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.55330, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 1.0133 - acc: 0.6360 - val_loss: 0.9405 - val_acc: 0.6508\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.55330 to 0.65080, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.8775 - acc: 0.6823 - val_loss: 0.8597 - val_acc: 0.6931\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.65080 to 0.69310, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.8261 - acc: 0.7026 - val_loss: 0.8255 - val_acc: 0.7069\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.69310 to 0.70690, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.7970 - acc: 0.7136 - val_loss: 0.8342 - val_acc: 0.7119\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.70690 to 0.71190, saving model to weights/temp_network.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.7728 - acc: 0.7241 - val_loss: 0.7825 - val_acc: 0.7167\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.71190 to 0.71670, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.7535 - acc: 0.7293 - val_loss: 0.7741 - val_acc: 0.7187\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.71670 to 0.71870, saving model to weights/temp_network.h5\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.7358 - acc: 0.7360 - val_loss: 0.7375 - val_acc: 0.7392\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.71870 to 0.73920, saving model to weights/temp_network.h5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.7212 - acc: 0.7417 - val_loss: 0.7556 - val_acc: 0.7299\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.73920\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.7041 - acc: 0.7486 - val_loss: 0.7050 - val_acc: 0.7527\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.73920 to 0.75270, saving model to weights/temp_network.h5\n",
            "10000/10000 [==============================] - 0s 16us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.7838561857935589\n",
            "Rewards :  -0.11956820306476994 Next Reward:  -0.02726166299702741 Accuracy :  0.7526999995112419\n",
            "Total reward :  -0.12682318173983484\n",
            "State input to Controller for training :  [1 0]\n",
            "Training RNN (States ip) :  [1, 48, 3, 32, 1, 32, 1, 32]\n",
            "Training RNN (Reward ip) :  [-0.11956821]\n",
            "Trial 15: Controller loss : 11.351250\n",
            "\n",
            "Generating random action to explore\n",
            "Actions :\n",
            "******************** Layer 1 ********************\n",
            "kernel :  [(1, 1.0), (3, 0.0)]\n",
            "filters :  [(32, 0.0), (48, 0.0), (64, 3.0)]\n",
            "******************** Layer 2 ********************\n",
            "kernel :  [(1, 1.0), (3, 0.0)]\n",
            "filters :  [(32, 0.0), (48, 2.0), (64, 0.0)]\n",
            "******************** Layer 3 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 1.0), (48, 0.0), (64, 0.0)]\n",
            "******************** Layer 4 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 1.0), (48, 0.0), (64, 0.0)]\n",
            "\n",
            "Predicted actions :  [1, 64, 1, 48, 3, 32, 3, 32]\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 1.3610 - acc: 0.5033 - val_loss: 0.8726 - val_acc: 0.6776\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.67760, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.8118 - acc: 0.7053 - val_loss: 0.7592 - val_acc: 0.7310\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.67760 to 0.73100, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.7336 - acc: 0.7363 - val_loss: 0.7183 - val_acc: 0.7472\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.73100 to 0.74720, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.6782 - acc: 0.7588 - val_loss: 0.6995 - val_acc: 0.7467\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.74720\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.6468 - acc: 0.7705 - val_loss: 0.6468 - val_acc: 0.7710\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.74720 to 0.77100, saving model to weights/temp_network.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.6173 - acc: 0.7792 - val_loss: 0.6344 - val_acc: 0.7737\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.77100 to 0.77370, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.5901 - acc: 0.7890 - val_loss: 0.5881 - val_acc: 0.7890\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.77370 to 0.78900, saving model to weights/temp_network.h5\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.5668 - acc: 0.7958 - val_loss: 0.5653 - val_acc: 0.7983\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.78900 to 0.79830, saving model to weights/temp_network.h5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.5517 - acc: 0.8018 - val_loss: 0.5661 - val_acc: 0.7961\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.79830\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 4s 58us/step - loss: 0.5316 - acc: 0.8081 - val_loss: 0.5493 - val_acc: 0.8008\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.79830 to 0.80080, saving model to weights/temp_network.h5\n",
            "10000/10000 [==============================] - 0s 19us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.7872449492571195\n",
            "Rewards :  0.01694381731780359 Accuracy :  0.8008000031113625\n",
            "Generating random action to explore\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 69us/step - loss: 1.5349 - acc: 0.4379 - val_loss: 1.0232 - val_acc: 0.6520\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.65200, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.8878 - acc: 0.6838 - val_loss: 0.8215 - val_acc: 0.7134\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.65200 to 0.71340, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.7801 - acc: 0.7199 - val_loss: 0.7599 - val_acc: 0.7277\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.71340 to 0.72770, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.7359 - acc: 0.7355 - val_loss: 0.7786 - val_acc: 0.6993\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.72770\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.7036 - acc: 0.7482 - val_loss: 0.6941 - val_acc: 0.7478\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.72770 to 0.74780, saving model to weights/temp_network.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.6834 - acc: 0.7555 - val_loss: 0.6819 - val_acc: 0.7561\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.74780 to 0.75610, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.6611 - acc: 0.7649 - val_loss: 0.6637 - val_acc: 0.7644\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.75610 to 0.76440, saving model to weights/temp_network.h5\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.6397 - acc: 0.7711 - val_loss: 0.6448 - val_acc: 0.7768\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.76440 to 0.77680, saving model to weights/temp_network.h5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.6270 - acc: 0.7771 - val_loss: 0.6563 - val_acc: 0.7607\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.77680\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.6189 - acc: 0.7793 - val_loss: 0.6178 - val_acc: 0.7837\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.77680 to 0.78370, saving model to weights/temp_network.h5\n",
            "10000/10000 [==============================] - 0s 21us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.7865359593556277\n",
            "Rewards :  0.014462352662582301 Next Reward:  -0.002481464655221288 Accuracy :  0.7836999997496605\n",
            "Total reward :  -0.11236082907725253\n",
            "State input to Controller for training :  [1 0]\n",
            "Training RNN (States ip) :  [1, 64, 1, 48, 3, 32, 3, 32]\n",
            "Training RNN (Reward ip) :  [0.01446235]\n",
            "Trial 16: Controller loss : 11.163523\n",
            "\n",
            "Generating random action to explore\n",
            "Actions :\n",
            "******************** Layer 1 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 1.0), (48, 0.0), (64, 0.0)]\n",
            "******************** Layer 2 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 0.0), (48, 0.0), (64, 3.0)]\n",
            "******************** Layer 3 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 0.0), (48, 2.0), (64, 0.0)]\n",
            "******************** Layer 4 ********************\n",
            "kernel :  [(1, 0.0), (3, 2.0)]\n",
            "filters :  [(32, 0.0), (48, 0.0), (64, 3.0)]\n",
            "\n",
            "Predicted actions :  [3, 32, 3, 64, 3, 48, 3, 64]\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 1.0726 - acc: 0.6089 - val_loss: 0.7376 - val_acc: 0.7273\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.72730, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.6648 - acc: 0.7598 - val_loss: 0.6176 - val_acc: 0.7802\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.72730 to 0.78020, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.5895 - acc: 0.7875 - val_loss: 0.6094 - val_acc: 0.7776\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.78020\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.5336 - acc: 0.8108 - val_loss: 0.5257 - val_acc: 0.8146\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.78020 to 0.81460, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.5007 - acc: 0.8211 - val_loss: 0.5049 - val_acc: 0.8249\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.81460 to 0.82490, saving model to weights/temp_network.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.4784 - acc: 0.8313 - val_loss: 0.4656 - val_acc: 0.8374\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.82490 to 0.83740, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.4421 - acc: 0.8445 - val_loss: 0.4619 - val_acc: 0.8330\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.83740\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.4292 - acc: 0.8484 - val_loss: 0.4710 - val_acc: 0.8262\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.83740\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.4118 - acc: 0.8544 - val_loss: 0.4253 - val_acc: 0.8520\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.83740 to 0.85200, saving model to weights/temp_network.h5\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.3934 - acc: 0.8607 - val_loss: 0.4237 - val_acc: 0.8510\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.85200\n",
            "10000/10000 [==============================] - 0s 24us/step\n",
            "\n",
            "Manager: EWA Accuracy =  0.7996287671030324\n",
            "Rewards :  0.06546403873702367 Accuracy :  0.8519999980926514\n",
            "Prediction action from Controller\n",
            "State input to Controller for Action :  [1. 0.]\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 1.1849 - acc: 0.5736 - val_loss: 0.7981 - val_acc: 0.7111\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.71110, saving model to weights/temp_network.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 0.7288 - acc: 0.7357 - val_loss: 0.6848 - val_acc: 0.7479\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.71110 to 0.74790, saving model to weights/temp_network.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 0.6562 - acc: 0.7631 - val_loss: 0.6423 - val_acc: 0.7707\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.74790 to 0.77070, saving model to weights/temp_network.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 0.6176 - acc: 0.7785 - val_loss: 0.6056 - val_acc: 0.7796\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.77070 to 0.77960, saving model to weights/temp_network.h5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 4s 69us/step - loss: 0.5828 - acc: 0.7899 - val_loss: 0.5790 - val_acc: 0.7964\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.77960 to 0.79640, saving model to weights/temp_network.h5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 4s 69us/step - loss: 0.5510 - acc: 0.8034 - val_loss: 0.5458 - val_acc: 0.8049\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.79640 to 0.80490, saving model to weights/temp_network.h5\n",
            "Epoch 7/10\n",
            "36250/60000 [=================>............] - ETA: 1s - loss: 0.5247 - acc: 0.8119"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b2e39bade552>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_sess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mtemp_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontroller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## will get the next action; new model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0mnext_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_rewards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_state_space_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0mnext_reward\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnext_reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mreward\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mnext_reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-b2e39bade552>\u001b[0m in \u001b[0;36mget_rewards\u001b[0;34m(self, model_fn, actions)\u001b[0m\n\u001b[1;32m     73\u001b[0m                                                  \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                                                  \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                                                  save_weights_only=True)])\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights/temp_network.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w__dcYtzCJjc",
        "colab_type": "code",
        "outputId": "a322b022-8214-46d6-a4c6-71a78f1c8ad7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "plt.xticks(range(1,20,2))\n",
        "plt.xlabel('Episodes')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.plot(accuracy_plot)\n",
        "plt.savefig('plots/ac_accuracy.png')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npVRAmiCUUkoFpAlCKaVUQP8fNfOHITg2kH4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJ4yLC6JQHbr",
        "colab_type": "code",
        "outputId": "943fb712-1ba7-413c-a7b6-44c4767ced4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plt.xticks(range(1,20,2))\n",
        "plt.xlabel('Episodes')\n",
        "plt.ylabel('Rewards')\n",
        "plt.plot(reward_plot)\n",
        "plt.savefig('plots/ac_reward.png')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEGCAYAAABLgMOSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ovx1OJW6CJmT",
        "colab_type": "code",
        "outputId": "4fe85bfe-6a74-4d80-aa0d-98fe48d3c7c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plt.xticks(range(1,20,2))\n",
        "plt.xlabel('Episodes')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(loss_plot)\n",
        "plt.savefig('plots/ac_loss.png')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaA7BTBZQfpk",
        "colab_type": "code",
        "outputId": "36d37f28-5027-495a-cb96-1dcc76bde773",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.var(reward_plot)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0019968118096116917"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22yvPAemWk0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}